\documentclass[10pt, a4paper, landscape]{extarticle}

% -----packages-----
\usepackage{multicol} % for multiple columns
\usepackage[landscape]{geometry} % for landscape
\usepackage{parskip} % remove text indentation
\usepackage{graphicx} % for scale tables
\usepackage{enumitem} % indent of lists
\usepackage{tikz} % for plots
\usepackage{hyperref} % for hyperlinks
\usepackage{amsmath} % for writing normal text on equations
\usepackage{scrlayer-scrpage} % page foot
\usepackage[compact]{titlesec} % titles spacing

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% WATERMARK (NOT PERMANENT...) %%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{draftwatermark}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% -----page customization-----
\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} % margins configuration
\pagenumbering{gobble} % remove page numeration
\setlength{\parskip}{0cm} % paragraph skip length
% title spacing:
\titlespacing{\section}{0pt}{2ex}{1ex}
\titlespacing{\subsection}{0pt}{1ex}{0ex}
\titlespacing{\subsubsection}{0pt}{0.5ex}{0ex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% WATERMARK PROPERTIES %%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\SetWatermarkText{DRAFT}
\SetWatermarkScale{3}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% -----document-----
\begin{document}

\cfoot{\href{https://github.com/marcelomijas/econometrics-cheatsheet}{\normalfont \footnotesize Version ts0.3-en - github.com/marcelomijas/econometrics-cheatsheet}}
\setlength{\footskip}{12pt}

\begin{multicols}{3} % set columns to 3

\begin{center}
	\textbf{\LARGE \href{https://github.com/marcelomijas/econometrics-cheatsheet}{Time Series Cheat Sheet}}
	\\ {\footnotesize By Marcelo Moreno - King Juan Carlos University} 
	\\ {\footnotesize As part of the Econometrics Cheat Sheet Project}
\end{center}

\colorbox{yellow}{THIS IS A WORK IN PROGRESS}
\\ \colorbox{yellow}{NOT INTENDEND FOR GENEAL PURPOSE}

\section*{Basic concepts}
	\subsection*{Definitions}
		\textbf{Time series} - is a succession of quantitative observations of a phenomena ordered in time.
		\\ There are some variations of time series:
		\begin{itemize}[leftmargin=*]
			\item \textbf{Panel data} - consist of a time series for each observation of a cross section.
			\item \textbf{Pooled cross sections} - combines cross sections from different time periods.
		\end{itemize}
		\textbf{Stochastic process} - sequence of random variables that are indexed in time.
	\subsection*{Components of a time series}
		\begin{itemize}[leftmargin=*]
			\item \textbf{Trend} - is the long-term general movement of a series.
			\item \textbf{Seasonal variations} - are periodic oscillations that are produced in a period equal or inferior to a year, and can be easily identified on different years (usually are the result of climatology reasons).
			\item \textbf{Cyclical variations} - are periodic oscillations that are produced in a period greater than a year (are the result of the economic cycle).
			\item \textbf{Residual variations} - are movements that do not follow a recognizable periodic oscillation (are the result of eventual non-permanent phenomena that can affect the studied variable in a given moment).
		\end{itemize}

	\subsection*{Type of time series models}
		\begin{itemize}[leftmargin=*]
			\item \textbf{Static models} - the relation between $y$ and $x$'s is contemporary. Conceptually:
			\begin{center}
				$y_t = \beta_0 + \beta_1 x_t + u_t$
			\end{center}
			\item \textbf{Distributed-lag models} - the relation between $y$ and $x$'s is not contemporary. Conceptually:
			\begin{center}
				$y_t = \beta_0 + \beta_1 x_t + \beta_2 x_{t-1} + ... + \beta_{q+1} x_{t-q} + u_t$
			\end{center}
			The long term cumulative effect in $y$ when $\Delta x$ is:
			 \begin{center}
			 	$\beta_1 + \beta_2 + ... + \beta_{q+1}$
			 \end{center}
		\end{itemize}

\columnbreak

\section*{Assumptions and properties}
	\subsection*{OLS model assumptions under time series}
		Under this assumptions, the estimators of the OLS parameters will present good properties. \textbf{Gauss-Markov assumptions extended applied to time series}:
		\begin{enumerate}[leftmargin=*, label=ts\arabic*.]
			\item \textbf{Parameters linearity and weak dependence}.
			\begin{enumerate}[leftmargin=*, label=\alph*.]
				\item $y_t$ must be a linear function of the $\beta$'s.
				\item The stochastic $\lbrace(x_t, y_t): t = 1, 2, ..., T\rbrace$ is stationary and weakly dependent.
			\end{enumerate} 
			\item \textbf{No perfect collinearity}.
			\begin{itemize}[leftmargin=*]
				\item There are no independent variables that are constant: $Var(x_j) \neq 0$
				\item There is not an exact linear relation between independent variables.
			\end{itemize}
			\item \textbf{Conditional mean zero and correlation zero}.
			\begin{enumerate}[leftmargin=*, label=\alph*.]
				\item There are no systematic errors: $E(u_t | x_{1t}, ..., x_{kt}) = E(u_t) = 0 \rightarrow$ \textbf{strong exogeneity} (a implies b).
				\item There are no relevant variables left out of the model: $Cov(x_{jt} , u_t) = 0$ for any $j = 1, ..., k \rightarrow$ \textbf{weak exogeneity}.
			\end{enumerate}
			\item \textbf{Homoscedasticity}. The variability of the residuals is the same for any $t$: $Var(u_t | x_{1t}, ..., x_{kt}) = \sigma^2$
			\item \textbf{No auto-correlation}. The residuals do not contain information about other residuals: $Corr(u_t, u_s | x) = 0$ for any given $t \neq s$.
			\item \textbf{Normality}. The residuals are independent and identically distributed: $u \sim N(0,\sigma^2)$
			\item \textbf{Data size}. The number of observations available must be greater than $(k + 1)$ parameters to estimate. (IS already satisfied under asymptotic situations)
		\end{enumerate}	
	\subsection*{Asymptotic properties of OLS}
		Under the econometric model assumptions and the Central Limit Theorem:
		\begin{itemize}[leftmargin=*]
			\item Hold (1) to (3a): OLS is \textbf{unbiased}. $E(\hat{\beta}_j) = \beta_j$
			\item Hold (1) to (3): OLS is \textbf{consistent}. $plim(\hat{\beta}_j) = \beta_j$ (to (3b) left out (3a), weak exogeneity, biased but consistent)
			\item Hold (1) to (5): \textbf{asymptotic normality} of OLS (then, (6) is necessarily satisfied): $u \sim_a N(0,\sigma^2)$.
			\item Hold (1) to (5): \textbf{unbiased estimate of $\sigma^2$}. $E(\hat{\sigma}^2) = \sigma^2$
			\item Hold (1) to (5): OLS is \textcolor{blue}{BLUE} (Best Linear Unbiased Estimator) or \textbf{efficient}. 
			\item Hold (1) to (6): hypothesis testing and confidence intervals can be done reliably.
		\end{itemize}

\section*{Trends and seasonality}
	\subsection*{Trends}
		Two time series can have the same (or contrary) trend, that should lend to a high level of correlation. This, can provoke a false appearance of causality, the problem is in what is known as \textbf{spurious regression} (the non-fulfillment of ts3). For example, given the model:
		\begin{center}
			$y_t = \beta_0 + \beta_1 x_t + u_t$
		\end{center}
		where:
		\begin{center}
			$y_t = \alpha_0 + \alpha_1 Trend + e_t$
			\\ $x_t = \gamma_0 + \gamma_1 Trend + v_t$
		\end{center}
		Adding a trend to the model can solve the problem:
		\begin{center}
			$y_t = \beta_0 + \beta_1 x_t + \beta_2 Trend + u_t$
		\end{center}
		The trend can be linear or non-linear (quadratic, cubic, exponential, etc.)
	\subsection*{Seasionality}
		\setlength{\multicolsep}{0pt} % reduce vertical spacing betwen subsection and multicols
		\begin{multicols}{2} % set columns to 2
		A time series with can manifest seasionality. That is, the series is subject to a seasonal variations or pattern, usually related to climatology conditions.
		\\ For example, the GDP is usually higher in summer and lower in winter.
		\columnbreak
			\begin{tikzpicture}[scale=0.18]
				\draw[step=2, gray, very thin] (-10,-10) grid (10,10); % background grid
				\draw[thick, <->] (-10,10) node[anchor=south] {$y$} -- (-10,-10) -- (10,-10) node[anchor=north] {$t$}; %axis
				\draw[red, thick] plot [domain=-10:10] (\x,{-0.19 + 0.66 * \x}); % regression line
				\draw (-8,-7.2061) -- (-7.5676,-5.1908) -- (-7.1351,-8) -- (-6.7027,-2.3817) -- (-6.2703,-3.9695) -- (-5.8378,-1.1603) -- (-5.4054,-4.5802) -- (-4.973,0.855) -- (-4.5405,-1.5267) -- (-4.1081,-0.3053) -- (-3.6757,-4.5191) -- (-3.2432,-0.4885) -- (-2.8108,-2.3206) -- (-2.3784,-0.4275) -- (-1.9459,-4.2137) -- (-1.5135,0.3664) -- (-1.0811,-1.7099) -- (-0.6486,-0.5496) -- (-0.2162,-4.3969) -- (0.2162,1.0992) -- (0.6486,-1.0382) -- (1.0811,1.2824) -- (1.5135,-2.8702) -- (1.9459,1.7099) -- (2.3784,-1.0382) -- (2.8108,1.5267) -- (3.2432,-1.8321) -- (3.6757,3.3588) -- (4.1081,1.0992) -- (4.5405,4.2137) -- (4.973,0.916) -- (5.4054,6.2901) -- (5.8378,4.3969) -- (6.2703,6.5954) -- (6.7027,3.4198) -- (7.1351,8) -- (7.5676,6.1069) -- (8,6.9008);
			\end{tikzpicture}
		\end{multicols}
		This problem is part of what is known as \textbf{spurious regression} (the non-fulfillment of ts3). A seasonal adjustment can solve the problem.
		\\ A simple seasonal adjustment could be creating stational binary variables and adding them to the model. For example, for quarterly series:
		\begin{center}
			$y_t = \beta_0 + \beta_1 Q2_t + \beta_2 Q3_t + \beta_3 Q4_t + \beta_4 x_{1t} + ... + \beta_k x_{kt} + u_t$
		\end{center}
		Another way is to seasonaly adjust (sa) the variables, and then, do the regression with the final regression:
		\begin{center}
			$z_t = \beta_0 + \beta_1 Q2_t + \beta_2 Q3_t + \beta_3 Q4_t  + e_t \rightarrow (sa)\tilde{e}_t = (sa)\tilde{z}_t$
			$(sa)\tilde{y}_t = \beta_0 + \beta_1 (sa)\tilde{x}_{1t} + ... + \beta_k (sa)\tilde{x}_{kt} + u_t$
		\end{center}
		There are much better and complex methods to seasonaly adjust a time series.
		
\columnbreak

\section*{Stationarity}
	Strong exogeneity is violated in static models and distributed-lag models.
	\subsection*{Stationary and non-stationary process}
		\begin{itemize}[leftmargin=*]
			\item Stationary process - is the one in that the probability distribution are stable in time. If any collection of random variables are taken, and are shifted $h$ periods, the joint probability distribution should be inaltered.
			\begin{itemize}[leftmargin=*]
				\item Strong stationarity - if the mean is constant in time.
				\item Weak stationarity - $Cov(x_t, x_{x+h})$ only depends on $h$, not of $t$.
			\end{itemize}
			\item Non-stationary process - for example, a series with trend, at least the mean change with the time (at least).
		\end{itemize}
		Stationarity is good, $\beta_j$ stand unchanged in time.

\section*{Weak-dependent time series}
	How close the relationship between $x_t$ and $x_{t+h}$ is as the temporal distance between the series increases ($h$).  (it is good, can achieve Central Limit Theorem). It is different from the concept of stationarity.
	\\ Weak dependence: when $x_t$ and $x_{t+h}$ are almost independent as $h$ increases to infinity.
	\\ When $Corr(x_t, x_{t+h}) \rightarrow$ 0 when h $\rightarrow infinity$	


\section*{Moving average process order 1}
	MA(1)
	\\ iid (independent and identically distributed)
	\\ $x_t = e_t + \alpha_1 e_{t-1}$ , $t=1,2,...,T$
	\\ is stationary and weak-dependent
	
\section*{Auto-regressive process order 1}
	AR(1)
	\\ iid
	\\ $y_t = \rho_1 y_{t-1} + u_t$
	\\ If $|\rho_1|<1$ in AR(1)
	\\ stable process
	\\ is stationary and weak dependent
	\\
	\\
	\\ A series with a trend cannot be stationary, but can be weak dependent (and OK if the model have included a Trend variable)
	
\columnbreak

\section*{Dummy variables and structural change in time series}
	Dummy (or binary) variables are used for qualitative information like sex, civil state, country, etc.
	\begin{itemize}[leftmargin=*]
		\item Get the \textbf{value of 1 in a given category, and 0 on the rest}.
		\item Are used to analyze and modeling \textbf{structural changes} in the model parameters.
	\end{itemize}
	If a qualitative variable have $m$ categories, we only have to include ($m-1$) dummy variables.
	\subsection*{Structural change}
		Structural change refers to changes in the values of the parameters of the econometric model produced by the effect of different sub-populations. Structural change can be included in the model through dummy variables.
		\\ The position of the dummy variable matters:
		\begin{itemize}[leftmargin=*]
			\item \textbf{On the intercept ($\beta_0$)} - represents the mean difference between the values produced by the structural change.
			\item \textbf{On the parameters that determines the slope of the regression line ($\beta_j$)} - represents the effect (slope) difference between the values produced by the structural change.
		\end{itemize}
		\textbf{The Chow's structural contrast} - when we want to analyze the existence of structural changes in all the model parameters, it is common to use a particular expression of the F contrast known as the Chow's contrast, where the null hypothesis is: $H_0: \text{No structural change}$ (non-asymptotic correlation)

\section*{Predictions}
	Two types of prediction:
	\begin{itemize}[leftmargin=*]
		\item Of the mean value of $y$ for a specific value of $x$.
		\item Of an individual value of $y$ for a specific value of $x$.
	\end{itemize}
	If the values of the variables ($x$) approximate to the mean values ($\overline{x}$), the confidence interval amplitude of the prediction will be shorter. 

\section*{Heteroscedasticity in time series}
	The residuals $u_i$ of the population regression function do not have the same variance $\sigma^2$:
	\begin{center}
		$Var(u|x) = Var(y|x) \neq \sigma^2$
	\end{center}
	Is the \textbf{breaking of the fifth (5) econometric model assumption}.
	\subsection*{Consequences}
		\begin{itemize}[leftmargin=*]
			\item OLS estimators still are unbiased.
			\item OLS estimators still are consistent.
			\item OLS is \textbf{not efficient} anymore, but still a LUE (Linear Unbiased Estimator).
			\item \textbf{Variance estimations of the estimators are biased}: the construction of confidence intervals and the hypothesis contrast are not reliable.
		\end{itemize}
	\subsection*{Detection}
		\begin{itemize}[leftmargin=*]
			\setlength{\multicolsep}{0pt} % reduce vertical spacing betwen subsection and multicols
			\setlength{\columnsep}{20pt} % increment spacing between columns
			\begin{multicols}{3} % set columns to 3
			\item \textbf{Graphical analysis} - look for scatter patterns on $x$ vs. $u$ or $x$ vs. $y$ plots.

			\columnbreak
			\vspace*{-23pt}

			\begin{tikzpicture}[scale=0.108]
				\draw[step=2, gray, very thin] (-10,-10) grid (10,10); % grid
				\draw[thick,->] (-10,0) -- (10,0) node[anchor=north] {$x$}; % x axis
				\draw[thick,-] (-10,-10) -- (-10,10) node[anchor=west] {$u$}; % u axis
				\draw plot [domain=0:17, samples=50] ({\x - 9},{-0.5 * rand * \x - 1}); % data points
				\draw[thick, dashed, red, -latex] plot [domain=1:17] ({\x - 10},{-0.5 * \x - 1}); % lower red arrow
				\draw[thick, dashed, red, -latex] plot [domain=1:17] ({\x - 10},{0.5 * \x - 1}); % upper red arrow
			\end{tikzpicture}

			\columnbreak
			\vspace*{-24pt}

			\begin{tikzpicture}[scale=0.108]
				\draw[step=2, gray, very thin] (-10,-10) grid (10,10); % grid
				\draw[thick,<->] (-10,10) node[anchor=west] {$y$} -- (-10,-10) -- (10,-10) node[anchor=south] {$x$}; % axis
				\draw plot [domain=0:13, samples=50] ({\x -9},{(-0.65 * rand * \x) + 0.6 * \x - 8}); % data points
				\draw[thick, dashed, red, -latex] plot [domain=0:12] ({\x - 9},{-0.06 * \x - 8.5}); % lower red arrow
				\draw[thick, dashed, red, -latex] plot [domain=0:12] ({\x -9},{1.25 * \x - 7.2}); % upper red arrow
			\end{tikzpicture}
			\end{multicols}
			\item \textbf{Formal tests} - White, Bartlett, Breusch-Pagan, etc. Commonly, the null hypothesis: $H_0 = \text{Homoscedasticity}$
		\end{itemize}
		\textbf{DURBIN WATSON EXPLANATION AND GRAPHICAL ANALYSIS (AND MOST COMMON VALUES?)}

	\subsection*{Correction}
		\begin{itemize}[leftmargin=*]
			\item Use OLS with a variance-covariance matrix estimator robust to heteroscedasticity, for example, the one proposed by White.
			\item If the variance structure is known, make use of Weighted Least Squares (WLS) or Generalized Least Squares (GLS).
			\item If the variance structure is not known, make use of Feasible Weighted Least Squared (FWLS), that estimates a possible variance, divides the model variables by it and then apply OLS.
			\item Make assumptions about the possible variance:
			\begin{itemize}[leftmargin=*]
				\item Supposing that $\sigma_i^2$ is proportional to $x_i$, divide the model variables by the square root of $x_i$ and apply OLS.
				\item Supposing that $\sigma_i^2$ is proportional to $x_i^2$, divide the model variables by $x_i$ and apply OLS.
			\end{itemize}
			\item Make a new model specification, for example, logarithmic transformation.
		\end{itemize}

\section*{Auto-correlation}
	The residual of any observation, $u_t$, is correlated with the residual of any other observation. The observations are not independent.
	\begin{center}
		$Corr(u_t, u_s | x) \neq 0$ for any $t \neq s$
	\end{center}
	The ``natural" context of this phenomena is time series. Is the \textbf{breaking of the sixth (6) econometric model assumption}.
	\subsection*{Consequences}
		\begin{itemize}[leftmargin=*]
			\item OLS estimators still are unbiased.
			\item OLS estimators still are consistent.
			\item OLS is \textbf{not efficient} anymore, but still a LUE (Linear Unbiased Estimator).
			\item \textbf{Variance estimations of the estimators are biased}: the construction of confidence intervals and the hypothesis contrast are not reliable.
		\end{itemize}
	\subsection*{Detection}
		\begin{itemize}[leftmargin=*]
			\item \textbf{Graphical analysis} - look for scatter patterns on $u_{t-1}$ vs. $u_t$ or make use of a correlogram.
			\setlength{\multicolsep}{0pt} % reduce vertical spacing betwen subsection and multicols
			\setlength{\columnsep}{6pt} % increment spacing between columns
			\begin{multicols}{3} % set columns to 3
				\begin{center}
					\textbf{\footnotesize AR}
				\end{center}
				\vspace{2.0pt}
				\begin{tikzpicture}[scale=0.11]
					\draw[step=2, gray, very thin] (-10,-10) grid (10,10); % grid
					\draw[thick,->] (-10,0) -- (10,0) node[anchor=south] {$u_{t-1}$}; % ut-1 axis
					\draw[thick,-] (-10,-10) -- (-10,10) node[anchor=west] {$u_t$}; % ut axis
					\draw plot [only marks, mark=*, mark size=6, domain=-8:8, samples=50] (\x,{rnd * 6 + (-2 * (\x)^2 + 40) * 0.1}); % data points
					\draw[thick, dashed, red, -latex] plot [domain=-8:8] (\x,{3 + (-2 * (\x)^2 + 40) * 0.1}); % red arrow
				\end{tikzpicture}

				\columnbreak

				\begin{center}
					\textbf{\footnotesize AR(+)}
				\end{center}
				\begin{tikzpicture}[scale=0.11]
					\draw[step=2, gray, very thin] (-10,-10) grid (10,10); % grid
					\draw[thick,->] (-10,0) -- (10,0) node[anchor=north] {$ u_{t-1}$}; % ut-1 axis
					\draw[thick,-] (-10,-10) -- (-10,10) node[anchor=west] {$u_t$}; % ut axis
					\draw plot [only marks, mark=*, mark size=6, domain=-8:8, samples=25] (\x,{rnd * 6 + 0.5 * \x - 3}); % data points
					\draw[thick, dashed, red, -latex] plot [domain=-8:8] (\x,{3 + 0.5 * \x - 3}); % red arrow
				\end{tikzpicture}

				\columnbreak

				\begin{center}
					\textbf{\footnotesize AR(-)}
				\end{center}
				\begin{tikzpicture}[scale=0.11]
					\draw[step=2, gray, very thin] (-10,-10) grid (10,10); % grid
					\draw[thick,->] (-10,0) -- (10,0) node[anchor=south] {$u_{t-1}$}; % ut-1 axis
					\draw[thick,-] (-10,-10) -- (-10,10) node[anchor=west] {$u_t$}; % ut axis
					\draw plot [only marks, mark=*, mark size=6, domain=-8:8, samples=25] (\x,{rnd * 6 - 0.5 * \x - 3}); % data points
					\draw[thick, dashed, red, -latex] plot [domain=-8:8] (\x,{3 - 0.5 * \x - 3}); % red arrow
				\end{tikzpicture}
			\end{multicols}
			\item \textbf{Formal tests} - Durbin-Watson, Breusch-Godfrey, etc. Commonly, the null hypothesis: $H_0: \text{No auto-correlation}$
		\end{itemize}
	\subsection*{Correction}
		\begin{itemize}[leftmargin=*]
			\item Use OLS with a variance-covariance matrix estimator robust to auto-correlation, for example, the one proposed by Newey-West.
			\item Use Generalized Least Squares. Supposing $y_t = \beta_0 + \beta_1 x_t + u_t$, with $u_t = \rho u_{t-1} + \varepsilon_t$, where $|\rho| < 1$ and $\varepsilon_t$ is white noise.
			\begin{itemize}[leftmargin=*]
				\item If $\rho$ is known, create a quasi-differentiated model where $u_t$ is white noise and estimate it by OLS.
				\item If $\rho$ is not known, estimate it by -for example- the Cochrane-Orcutt method, create a quasi-differentiated model where $u_t$ is white noise and estimate it by OLS.
			\end{itemize}
		\end{itemize}

\section*{Endogeneity}

\end{multicols}

\end{document}